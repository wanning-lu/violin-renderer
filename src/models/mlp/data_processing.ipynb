{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Run parse_data\n",
    "%run ~/violin-renderer/src/data/parse_data.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions to normalize data\n",
    "def scale_timings(column):\n",
    "    return column / 384\n",
    "\n",
    "def scale_pitch(column):\n",
    "    return column / 128\n",
    "\n",
    "# helper functions to convert to duration and use (onset, duration) instead of (onset, offset)\n",
    "def set_duration(start, end):\n",
    "    return end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile all training data into one big matrix and normalize\n",
    "# @return: np array of normalized notes for both source input and ground truth\n",
    "def processed_training_datasets():\n",
    "    # Load the training dataset\n",
    "    training_X, training_y = load_training_data()\n",
    "\n",
    "    # combine into an array\n",
    "    training_source_inputs = []\n",
    "    training_ground_truths = []\n",
    "    for (source_input_song, ground_truth_song) in zip(training_X.values(), training_y.values()):\n",
    "        for (note, timing) in zip(source_input_song, ground_truth_song):\n",
    "            # Cheat: Remove notes that have offset greater than 384 so we can normalize better\n",
    "            if note[1] < 384:\n",
    "                training_source_inputs.append(note)\n",
    "                training_ground_truths.append(timing)\n",
    "\n",
    "    # convert to np arrays\n",
    "    training_source_inputs = np.array(training_source_inputs)\n",
    "    training_ground_truths = np.array(training_ground_truths)\n",
    "\n",
    "    # normalizing the input\n",
    "    training_source_inputs[:, 0] = scale_timings(training_source_inputs[:, 0])\n",
    "    training_source_inputs[:, 1] = scale_timings(training_source_inputs[:, 1])\n",
    "    training_source_inputs[:, 2] = scale_pitch(training_source_inputs[:, 2])\n",
    "\n",
    "    # changing the offset feature to duration\n",
    "    # training_source_inputs[:, 1] = set_duration(training_source_inputs[:, 0], training_source_inputs[:, 1])\n",
    "    # training_ground_truths[:, 1] = set_duration(training_ground_truths[:, 0], training_ground_truths[:, 1])\n",
    "\n",
    "    return training_source_inputs, training_ground_truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing_source_inputs = []\n",
    "# testing_ground_truths = []\n",
    "# for (source_input_song, ground_truth_song) in zip(testing_X, testing_y):\n",
    "#     for (note, timing) in zip(source_input_song, ground_truth_song):\n",
    "#     testing_source_inputs.extend(source_input_notes)\n",
    "#     testing_ground_truths.extend(ground_truth_timings)\n",
    "\n",
    "# testing_source_inputs = np.array(testing_source_inputs)\n",
    "# testing_ground_truths = np.array(testing_ground_truths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "music-gen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
