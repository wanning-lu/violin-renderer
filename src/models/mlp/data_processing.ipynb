{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Run parse_data\n",
    "%run ~/violin-renderer/src/data/parse_data.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions to normalize data\n",
    "def scale_timings(column):\n",
    "    return column / (64 * 24) # beats * resolution\n",
    "\n",
    "def scale_pitch(column):\n",
    "    # return column / 128\n",
    "    return 0 # ignore pitch\n",
    "\n",
    "# helper functions to convert to duration and use (onset, duration) instead of (onset, offset)\n",
    "def set_duration(start, end):\n",
    "    return end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile all training data into one big matrix and normalize\n",
    "# @return: np array of normalized notes of source input and np array of ground truth\n",
    "def processed_training_datasets():\n",
    "    # Load the training dataset\n",
    "    training_X, training_y = load_training_data()\n",
    "\n",
    "    # combine into a matrix\n",
    "    training_source_inputs = []\n",
    "    training_ground_truths = []\n",
    "    for (source_input_song, ground_truth_song) in zip(training_X.values(), training_y.values()):\n",
    "        for (note, timing) in zip(source_input_song, ground_truth_song):\n",
    "            # Cheat: Remove notes that have offset greater than a set threshold so we can normalize better\n",
    "            if note[1] < 64 * 24: # beats * resolution\n",
    "                training_source_inputs.append(note)\n",
    "                training_ground_truths.append(timing)\n",
    "\n",
    "    # convert to an np arrays\n",
    "    training_source_inputs = np.array(training_source_inputs)\n",
    "    training_ground_truths = np.array(training_ground_truths)\n",
    "\n",
    "    # changing the offset feature to duration\n",
    "    # training_source_inputs[:, 1] = set_duration(training_source_inputs[:, 0], training_source_inputs[:, 1])\n",
    "    # training_ground_truths[:, 1] = set_duration(training_ground_truths[:, 0], training_ground_truths[:, 1])\n",
    "\n",
    "    # normalizing the input\n",
    "    training_source_inputs[:, 0] = scale_timings(training_source_inputs[:, 0])\n",
    "    training_source_inputs[:, 1] = scale_timings(training_source_inputs[:, 1])\n",
    "    training_source_inputs[:, 2] = scale_pitch(training_source_inputs[:, 2])\n",
    "\n",
    "    return training_source_inputs, training_ground_truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile all testing data into one big matrix and normalize\n",
    "# @return: map of { path : np array of normalized notes of source input } and { path : np array of ground truth }\n",
    "def processed_testing_datasets():\n",
    "    # Load the training dataset\n",
    "    testing_X, testing_y = load_testing_data()\n",
    "\n",
    "    testing_source_inputs = {}\n",
    "    testing_ground_truths = {}\n",
    "\n",
    "    # normalize each song separately\n",
    "    for (source_input_pair, ground_truth_pair) in zip(testing_X.items(), testing_y.items()):\n",
    "        source_input_song = source_input_pair[1]\n",
    "        ground_truth_song = ground_truth_pair[1]\n",
    "\n",
    "        filtered_source_input = []\n",
    "        filtered_ground_truth = []\n",
    "        for (note, timing) in zip(source_input_song, ground_truth_song):\n",
    "            # Cheat: Remove notes that have offset greater than a set threshold so we can normalize better\n",
    "            if note[1] < 64 * 24: # beats * resolution\n",
    "                filtered_source_input.append(note)\n",
    "                filtered_ground_truth.append(timing)\n",
    "\n",
    "        # convert to np arrays\n",
    "        filtered_source_input = np.array(filtered_source_input)\n",
    "        filtered_ground_truth = np.array(filtered_ground_truth)\n",
    "\n",
    "        # changing the offset feature to duration\n",
    "        # testing_source_inputs[:, 1] = set_duration(testing_source_inputs[:, 0], testing_source_inputs[:, 1])\n",
    "        # testing_ground_truths[:, 1] = set_duration(testing_ground_truths[:, 0], testing_ground_truths[:, 1])\n",
    "\n",
    "        # normalizing the input\n",
    "        filtered_source_input[:, 0] = scale_timings(filtered_source_input[:, 0])\n",
    "        filtered_source_input[:, 1] = scale_timings(filtered_source_input[:, 1])\n",
    "        filtered_source_input[:, 2] = scale_pitch(filtered_source_input[:, 2])\n",
    "\n",
    "        # append to map\n",
    "        source_input_song_path = source_input_pair[0]\n",
    "        ground_truth_song_path = ground_truth_pair[0]\n",
    "        testing_source_inputs[source_input_song_path] = filtered_source_input\n",
    "        testing_ground_truths[ground_truth_song_path] = filtered_ground_truth\n",
    "\n",
    "    return testing_source_inputs, testing_ground_truths"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "music-gen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
