{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1707100535892,
     "user": {
      "displayName": "Wanning Lu",
      "userId": "09623306388777366715"
     },
     "user_tz": 480
    },
    "id": "ot-KHBHSzKbw"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "%run ~/violin-renderer/src/misc/parse.ipynb\n",
    "# %run ~/violin-renderer/src/misc/randomizer.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_DIR = \"/home/wanninglu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize GPU to move model/tensors onto\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1707100535892,
     "user": {
      "displayName": "Wanning Lu",
      "userId": "09623306388777366715"
     },
     "user_tz": 480
    },
    "id": "f1jvr3dhzKb1"
   },
   "outputs": [],
   "source": [
    "# load all the datasets\n",
    "training_X, training_y, testing_X, testing_y = load_from_paths(HOME_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1707100535893,
     "user": {
      "displayName": "Wanning Lu",
      "userId": "09623306388777366715"
     },
     "user_tz": 480
    },
    "id": "3FWYp4JezKb3"
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.actfn = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.actfn(x)\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 223,
     "status": "ok",
     "timestamp": 1707100536109,
     "user": {
      "displayName": "Wanning Lu",
      "userId": "09623306388777366715"
     },
     "user_tz": 480
    },
    "id": "71tpDyqOzKb3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (linear1): Linear(in_features=3, out_features=4, bias=True)\n",
       "  (actfn): ReLU()\n",
       "  (linear2): Linear(in_features=4, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize the MLP\n",
    "model = MLP(3, 4, 2)\n",
    "\n",
    "# transfer model to GPU\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1707100536109,
     "user": {
      "displayName": "Wanning Lu",
      "userId": "09623306388777366715"
     },
     "user_tz": 480
    },
    "id": "GrwKJZ87zKb4"
   },
   "outputs": [],
   "source": [
    "# Define our loss function (mean squared error) to be used in the grad descent step\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "# Performs the gradient descent steps\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1707100536110,
     "user": {
      "displayName": "Wanning Lu",
      "userId": "09623306388777366715"
     },
     "user_tz": 480
    },
    "id": "NAy7tNjezKb5"
   },
   "outputs": [],
   "source": [
    "# Trains the model inputted into the function.\n",
    "#\n",
    "# @param model The model object to be trained\n",
    "# @param optimizer The optimizing equation to use to train the model\n",
    "# @param input_notes The training input data\n",
    "# @param truth The actual output for the corresponding input\n",
    "# @param loss_module Equation for calculating the difference between generated and actual output\n",
    "# @param num_epochs Number of cycles to train the model\n",
    "def train_model_loop(model, optimizer, input_notes, truth, loss_module, num_epochs=5000):\n",
    "    # Set model to train mode\n",
    "    model.train()\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        ## Step 1: Move input data to device (only strictly necessary if we use GPU)\n",
    "        input_notes = input_notes.to(device)\n",
    "        truth = truth.to(device)\n",
    "\n",
    "        ## Step 2: Run the model on the input data\n",
    "        preds = model(input_notes)\n",
    "\n",
    "        ## Step 3: Calculate the loss\n",
    "        loss = loss_module(preds, truth)\n",
    "\n",
    "        ## Step 4: Perform backpropagation\n",
    "        # Before calculating the gradients, we need to ensure that they are all zero.\n",
    "        # The gradients would not be overwritten, but actually added to the existing ones.\n",
    "        optimizer.zero_grad()\n",
    "        # Perform backpropagation\n",
    "        loss.backward()\n",
    "\n",
    "        ## Step 5: Update the parameters\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16170,
     "status": "ok",
     "timestamp": 1707100552270,
     "user": {
      "displayName": "Wanning Lu",
      "userId": "09623306388777366715"
     },
     "user_tz": 480
    },
    "id": "YLbk6ATRzKb5",
    "outputId": "8251a5f0-4406-435a-8f57-d869f6829a82"
   },
   "outputs": [],
   "source": [
    "# train for EACH file (warning: may take a while!!)\n",
    "def train_model1():\n",
    "    for (input_notes, truth) in zip(training_X, training_y):\n",
    "        new_input_notes = torch.Tensor(input_notes)\n",
    "        new_truth = torch.Tensor(truth)\n",
    "\n",
    "        train_model_loop(model, optimizer, new_input_notes, new_truth, loss)\n",
    "    torch.save(model.state_dict(), 'mlp.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consolidates all the training data into one big matrix\n",
    "def train_model2():\n",
    "    all_input = []\n",
    "    all_truth = []\n",
    "    for (input_notes, truth) in zip(training_X, training_y):\n",
    "        all_input.extend(input_notes)\n",
    "        all_truth.extend(truth)\n",
    "        \n",
    "    all_input = torch.Tensor(all_input)\n",
    "    all_truth = torch.Tensor(all_truth)\n",
    "    train_model_loop(model, optimizer, all_input, all_truth, loss, 10000)\n",
    "    torch.save(model.state_dict(), 'mlp2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 158,
     "status": "ok",
     "timestamp": 1707100552271,
     "user": {
      "displayName": "Wanning Lu",
      "userId": "09623306388777366715"
     },
     "user_tz": 480
    },
    "id": "U_auXk9GzKb6",
    "outputId": "3fac618e-1428-49c7-c066-4f4e817df80d"
   },
   "outputs": [],
   "source": [
    "# this creates a dictionary of outputs for all pieces in the testing dataset\n",
    "#\n",
    "# @returns a dictionary mapping with key of file path and value of csv values\n",
    "def generate_output():\n",
    "    \n",
    "    testing_results = {}\n",
    "    test_paths = []\n",
    "\n",
    "    file = open('file_paths/testing_truth.txt','r')\n",
    "    lines = file.readlines()\n",
    "    for line in lines:\n",
    "        test_paths.append(line.strip())\n",
    "    \n",
    "    # generating an output for each piece in the testing input dataset\n",
    "    for i in range(len(testing_X)):\n",
    "        new_test_input = torch.Tensor(testing_X[i])\n",
    "        new_test_input = new_test_input.to(device)\n",
    "        \n",
    "        y_test = model(new_test_input)\n",
    "        y_test = y_test.tolist()\n",
    "        for j in range(len(y_test)):\n",
    "            y_test[j].append(testing_X[i][j][2])\n",
    "\n",
    "        testing_results[test_paths[i]] = y_test\n",
    "\n",
    "    return testing_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE_error():\n",
    "    testing_results = generate_output()\n",
    "    loss_values = []\n",
    "    for output_path, truth in zip(testing_results, testing_y):\n",
    "        output = testing_results[output_path]\n",
    "\n",
    "        print(output_path)\n",
    "\n",
    "        # pitch was only added so the result is able to be synthesized, we can remove it here\n",
    "        for i in range(len(output)):\n",
    "            output[i].pop()\n",
    "        output = torch.Tensor(output)\n",
    "        truth = torch.Tensor(truth)\n",
    "        loss_value = loss(output, truth) / len(output)\n",
    "        loss_values.append(loss_value)\n",
    "\n",
    "    return loss_values"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
