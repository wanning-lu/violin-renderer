{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "%run parse.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alright, let's try with one movement, one performer!\n",
    "X = parseInputFile('../bach-violin-dataset/dataset/source-input/emil-telmanyi/bwv1001/emil-telmanyi_bwv1001_mov1.csv')\n",
    "y = parseGroundtruthFile('../bach-violin-dataset/dataset/ground-truth/emil-telmanyi/bwv1001/emil-telmanyi_bwv1001_mov1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting with linear regression. For this, we only need one linear layer.\n",
    "# For now, we don't need to build our own module yet because linear regression is simple. However, for an MLP, we will need multiple layers.\n",
    "model = nn.Linear(4, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our loss function (mean squared error) to be used in the grad descent step\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "# Performs the gradient descent steps\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template code from https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial2/Introduction_to_PyTorch.html#The-Basics-of-PyTorch\n",
    "def train_model(model, optimizer, input, truth, loss_module, num_epochs=100):\n",
    "    # Set model to train mode\n",
    "    model.train()\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        ## Step 1: Move input data to device (only strictly necessary if we use GPU)\n",
    "        # data_inputs = data_inputs.to(device)\n",
    "        # data_labels = data_labels.to(device)\n",
    "\n",
    "        ## Step 2: Run the model on the input data\n",
    "        preds = model(input)\n",
    "\n",
    "        ## Step 3: Calculate the loss\n",
    "        loss = loss_module(preds, y)\n",
    "\n",
    "        ## Step 4: Perform backpropagation\n",
    "        # Before calculating the gradients, we need to ensure that they are all zero.\n",
    "        # The gradients would not be overwritten, but actually added to the existing ones.\n",
    "        optimizer.zero_grad()\n",
    "        # Perform backpropagation\n",
    "        loss.backward()\n",
    "\n",
    "        ## Step 5: Update the parameters\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, optimizer, X, y, loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
